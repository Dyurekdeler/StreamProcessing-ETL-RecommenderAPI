ORDER OF RUNNING APPLICATIONS IN PROJECT

1) Run Kafka project to load "product_view_history" table

2) Run Spark project to extract and transform bestseller data from source DB to target DB

3) Run SpringBoot project to serve the data to users

----------

BEFORE RUNNING PROJECT PLEASE DO THE STEP BELOW:

1) "product_view_history" table must be created in Postgresql database for Kafka Producer/Consumer apps. Create table script can be found in DBScripts/bestseller-db-script.txt

Note: "bestseller_product" and "products" tables are not needed to be created, they will be automatically created by Spark ETL process app. Table data backups are given as extra, they will not be used at all.

----------

TO RUN THE SPRINGBOOT REST API

Please make sure Java 8 is installed and JAVA_HOME environment variable is set correctly.

In "application.properties" file please change the database connection settings accordingly

Run Java Spring-Boot application in terminal as follows,

If using Windows OS:
	mvnw spring-boot:run

If using Linux OS:
	mvn spring-boot:run

----------

TO RUN THE KAFKA APP

Please make sure Apache Kafka is installed.

Run these two commands at the same time in two seperate terminals

bin/zookeeper-server-start.sh config/zookeeper.properties

kafka-server-start.sh config/server.properties

In ProductViewConsumer and ProductViewProducer files change database connections/properties accordingly

----------

TO RUN THE SPARK APP

In SparkETL and SparkETLTest files change the database connection accordingly

